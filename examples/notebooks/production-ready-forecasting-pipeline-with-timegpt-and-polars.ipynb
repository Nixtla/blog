{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data with Polars\n",
    "\n",
    "Let's start by loading into a Polars DataFrame the [M4 competition dataset](https://nixtlaverse.nixtla.io/datasetsforecast), which contains over 100,000 time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from nixtla import NixtlaClient\n",
    "from datasetsforecast.m4 import M4\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load a subset of the M4 hourly dataset to demonstrate the basics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load M4 hourly data\n",
    "m4_data = M4.load(directory='data/', group='Hourly')\n",
    "train_df = m4_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting pandas DataFrames to Polars is straightforward with `pl.from_pandas()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to Polars for better performance\n",
    "train_pl = pl.from_pandas(train_df)\n",
    "\n",
    "print(f\"Dataset shape: {train_pl.shape}\")\n",
    "print(train_pl.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select 10 time series for initial demo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 10 time series for initial demo\n",
    "sample_ids = train_pl.select(\"unique_id\").unique().limit(10)[\"unique_id\"].implode()\n",
    "\n",
    "# Filter the main dataframe using the sample IDs\n",
    "demo_df = train_pl.filter(pl.col(\"unique_id\").is_in(sample_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code:\n",
    "\n",
    "- The `select()` method chooses specific columns, `unique()` removes duplicates, and `limit()` restricts the results.\n",
    "- `implode()` converts the `unique_id` column to a list.\n",
    "- `filter()` filters the dataframe using sample IDs, while `is_in()` checks if values exist in the list.\n",
    "\n",
    "Next, we'll convert the integer timestamps to datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert integer timestamps to datetime\n",
    "base_datetime = pl.datetime(2020, 1, 1)\n",
    "demo_long = demo_df.with_columns([\n",
    "    (base_datetime + pl.duration(hours=pl.col(\"ds\") - 1)).alias(\"ds\")\n",
    "])\n",
    "\n",
    "# Keep only required columns and filter out missing values\n",
    "demo_long = demo_long.select([\"unique_id\", \"ds\", \"y\"]).filter(pl.col(\"y\").is_not_null())\n",
    "print(demo_long.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this code:\n",
    "\n",
    "- `pl.datetime()` creates a base datetime and `pl.duration()` calculates time offsets from integer values.\n",
    "- `pl.col(\"ds\") - 1` converts 1-indexed timestamps to 0-indexed for proper hour calculation.\n",
    "- `select()` keeps only required columns and `is_not_null()` filters out missing values.\n",
    "\n",
    "## Performance at Scale: Polars vs Pandas\n",
    "\n",
    "Before diving into forecasting, let's demonstrate why Polars matters for larger datasets. We'll compare performance between pandas and Polars using the full M4 hourly dataset we already loaded.\n",
    "\n",
    "Start with creating a timing decorator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create timing decorator for accurate performance measurement\n",
    "def time_it(n_runs=10):\n",
    "    \"\"\"Decorator that runs a function n_runs times and returns average time.\"\"\"\n",
    "    def decorator(func):\n",
    "        def wrapper(*args, **kwargs):\n",
    "            times = []\n",
    "            result = None\n",
    "            for _ in range(n_runs):\n",
    "                start = time.time()\n",
    "                result = func(*args, **kwargs)\n",
    "                times.append(time.time() - start)\n",
    "            avg_time = sum(times) / len(times)\n",
    "            return result, avg_time\n",
    "        return wrapper\n",
    "    return decorator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the decorator to the functions and run 100 times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define operations as decorated functions\n",
    "@time_it(n_runs=100)\n",
    "def pandas_aggregation(df, ids):\n",
    "    return (\n",
    "        df[df[\"unique_id\"].isin(ids)]\n",
    "        .groupby(\"unique_id\")[\"y\"]\n",
    "        .agg([\"count\", \"mean\", \"std\"])\n",
    "    )\n",
    "\n",
    "@time_it(n_runs=100)\n",
    "def polars_aggregation(df, ids):\n",
    "    return df.filter(pl.col(\"unique_id\").is_in(ids)).group_by(\"unique_id\").agg([\n",
    "        pl.col(\"y\").count().alias(\"count\"),\n",
    "        pl.col(\"y\").mean().alias(\"mean\"),\n",
    "        pl.col(\"y\").std().alias(\"std\"),\n",
    "    ])\n",
    "\n",
    "# Compare performance with accurate timing\n",
    "sample_ids = [\"H1\", \"H2\", \"H3\", \"H4\", \"H5\"]\n",
    "\n",
    "pandas_stats, pandas_time = pandas_aggregation(train_df, sample_ids)\n",
    "polars_stats, polars_time = polars_aggregation(train_pl, sample_ids)\n",
    "\n",
    "print(f\"Pandas: {pandas_time:.4f}s | Polars: {polars_time:.4f}s | Speedup: {pandas_time / polars_time:.1f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polars is 3.2x faster than pandas for this operation.\n",
    "\n",
    "Next, let's compare memory usage between pandas and Polars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare memory usage\n",
    "import sys\n",
    "\n",
    "pandas_memory = sys.getsizeof(train_df) / 1024 / 1024  # MB\n",
    "polars_memory = train_pl.estimated_size('mb')\n",
    "\n",
    "print(f\"Pandas DataFrame: {pandas_memory:.1f} MB\")\n",
    "print(f\"Polars DataFrame: {polars_memory:.1f} MB\")\n",
    "print(f\"Memory savings: {((pandas_memory - polars_memory) / pandas_memory * 100):.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polars' columnar storage delivers 81% memory savings, enabling larger time series datasets without requiring distributed computing.\n",
    "\n",
    "## Basic Forecasting\n",
    "\n",
    "Now let's generate our first forecast using TimeGPT with a Polars DataFrame.\n",
    "\n",
    "First, we need to initialize the TimeGPT client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the API key from the .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize the TimeGPT client\n",
    "nixtla_client = NixtlaClient(\n",
    "    api_key=os.environ['NIXTLA_API_KEY']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TimeGPT's `forecast()` method accepts Polars DataFrames directly. Key parameters: `h` for forecast horizon, `freq` for data frequency, `time_col` and `target_col` to specify column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate forecasts directly from Polars DataFrame\n",
    "forecast_df = nixtla_client.forecast(\n",
    "    df=demo_long,\n",
    "    h=24,  # Forecast 24 hours ahead\n",
    "    freq='1h',\n",
    "    time_col='ds',\n",
    "    target_col='y'\n",
    ")\n",
    "\n",
    "print(f\"Generated {len(forecast_df)} forecasts for {len(forecast_df['unique_id'].unique())} series\")\n",
    "print(forecast_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Forecasts\n",
    "\n",
    "TimeGPT's built-in plotting functionality makes it easy to visualize both historical data and forecasts. The `plot()` method automatically handles Polars DataFrames and creates professional time series visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the forecast with historical data\n",
    "nixtla_client.plot(\n",
    "    df=demo_long, \n",
    "    forecasts_df=forecast_df, \n",
    "    time_col='ds', \n",
    "    target_col='y',\n",
    "    max_insample_length=100  # Show last 100 historical points\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows 8 different time series (H314, H188, H355, H390, H406, H414, H277, H76) with clear patterns:\n",
    "- **Historical data** appears in cyan lines showing various seasonal and trend patterns\n",
    "- **Forecasts** extend into the future (bright green lines) with different prediction patterns for each series\n",
    "- **Time series separation** displays each `unique_id` in its own subplot for easy comparison\n",
    "- **Prediction accuracy**: TimeGPT accurately captures each series' unique patternsâ€”seasonality, steady trends, and declines\n",
    "\n",
    "## Adding Confidence Intervals\n",
    "\n",
    "Understanding forecast uncertainty is crucial for inventory planning. TimeGPT provides prediction intervals without additional computation.\n",
    "\n",
    "To add [confidence intervals](https://www.nixtla.io/docs/forecasting/probabilistic/prediction_intervals), we can use the `level` parameter in the `forecast()` method. `level=[80, 95]` will generate 80% and 95% confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add confidence intervals\n",
    "forecast_with_intervals = nixtla_client.forecast(\n",
    "    df=demo_long,\n",
    "    h=24,\n",
    "    freq='1h',\n",
    "    time_col='ds',\n",
    "    target_col='y',\n",
    "    level=[80, 95]  # 80% and 95% confidence levels\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's analyze the forecast uncertainty. In the code below, we group by `unique_id` and calculate the mean of the 95% and 80% confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze forecast uncertainty\n",
    "uncertainty_stats = forecast_with_intervals.group_by('unique_id').agg([\n",
    "    (pl.col('TimeGPT-hi-95') - pl.col('TimeGPT-lo-95')).mean().alias('avg_95_interval'),\n",
    "    (pl.col('TimeGPT-hi-80') - pl.col('TimeGPT-lo-80')).mean().alias('avg_80_interval'),\n",
    "    pl.col('TimeGPT').std().alias('forecast_volatility')\n",
    "])\n",
    "\n",
    "print(\"Forecast Uncertainty Analysis:\")\n",
    "print(uncertainty_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's visualize the forecasts with confidence intervals to see the uncertainty bands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot forecasts with confidence intervals\n",
    "nixtla_client.plot(\n",
    "    df=demo_long,\n",
    "    forecasts_df=forecast_with_intervals,\n",
    "    time_col='ds',\n",
    "    target_col='y',\n",
    "    max_insample_length=100,\n",
    "    level=[80, 95]  # Display 80% and 95% confidence intervals\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot reveals key insights about forecast uncertainty:\n",
    "- **Confidence bands**: The subtle green shaded areas represent 80% (darker) and 95% (lighter) prediction intervals\n",
    "- **Variable uncertainty**: Series like H360 and H38 show wider bands indicating higher volatility\n",
    "- **Stable patterns**: H188 and H277 display tighter intervals, suggesting more predictable behavior\n",
    "- **Forecast horizon effect**: Uncertainty generally increases further into the future for most series\n",
    "\n",
    "## Cross-Validation for Model Validation\n",
    "\n",
    "While single forecasts are useful for demonstration, production systems require robust validation. TimeGPT's cross-validation feature lets you test forecast accuracy across multiple time windows.\n",
    "\n",
    "[Cross-validation](https://www.nixtla.io/docs/forecasting/evaluation/cross_validation) works by creating multiple train-test splits at different points in your time series, simulating how the model would have performed historically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform cross-validation with multiple windows\n",
    "cv_results = nixtla_client.cross_validation(\n",
    "    df=demo_long,  # Convert from Polars to pandas\n",
    "    h=24,           # 24-hour forecast horizon\n",
    "    n_windows=3,    # Test on 3 different time periods\n",
    "    step_size=24,   # Move forward 24 hours between windows\n",
    "    freq='1h',\n",
    "    time_col='ds',\n",
    "    target_col='y'\n",
    ")\n",
    "\n",
    "print(cv_results.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results include:\n",
    "- `cutoff`: The point where training data ends for each validation window\n",
    "- `y`: Actual observed values\n",
    "- `TimeGPT`: Forecasted values\n",
    "\n",
    "Now let's calculate error metrics for each time series and sort them by accuracy to identify the best and worst performing forecasts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate cross-validation performance metrics\n",
    "cv_performance = cv_results.with_columns([\n",
    "    (pl.col('y') - pl.col('TimeGPT')).abs().alias('MAE'),\n",
    "    ((pl.col('y') - pl.col('TimeGPT'))**2).alias('RMSE')\n",
    "]).group_by('unique_id').agg([\n",
    "    pl.col('MAE').mean().alias('avg_MAE'),\n",
    "    pl.col('RMSE').mean().sqrt().alias('avg_RMSE')\n",
    "]).sort('avg_MAE')\n",
    "\n",
    "print(\"Cross-validation performance summary:\")\n",
    "print(cv_performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results show clear performance differences across series:\n",
    "- **Top performers**: H188 (MAE: 0.08) and H277 (MAE: 0.13) achieve excellent accuracy\n",
    "- **Challenging series**: H38 and H76 show higher errors, indicating complex seasonal patterns\n",
    "- **Performance range**: MAE varies from 0.08 to 164, demonstrating TimeGPT adapts to different data characteristics"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
